% !Mode:: "TeX:UTF-8"
\chapter{引言}
\label{ch:intro}
\section{研究背景与意义}
\label{sec:background}
近几年来， 深度学习的迅猛发展赋予了机器越来越强的智能。 在这样的背景下， 无人驾驶作为最能够体现机器智能的"潜力股"之一，受到了各行各业的普遍关注。 无人驾驶要求车辆能够像人类一样识别道路场景，包括行人，车辆以及车道线等，并且能够根据这些信息高效地规划路径来实现与人类类似的驾驶行为。 在无人驾驶的整个技术栈中， 车辆的环境感知能力是最为关键的一环。 目前无人驾驶车辆依赖多种传感器感知环境， 譬如激光雷达(LIDAR)、摄像头、毫米波雷达等。 这些传感器的数据能够通过算法融合还原真实的三维环境，得到场景中物体的位姿与运动信息。

三维物体检测是无人驾驶环境感知的一个重要任务。该任务要求无人驾驶系统能够通过分析传感器采集的数据， 计算出场景中各个目标的三维坐标以及位姿。 相比于二维图像的物体检测任务，三维物体检测要更加困难。 这是因为维度诅咒(Curse of dimensionality)的存在： 当维度增加时，空间的体积增加得非常之快(以指数增加)，以致于可用的数据变得稀疏。 三维物体检测的一大挑战，就是三维数据的稀疏性。 目前无人驾驶中三维数据的获得主要是依靠激光雷达-高速旋转的激光发射器向周围发射激光，通过检测接收到反射回来光线的时间间隔来计算反射点的距离。激光雷达的线束对其分辨率有很大影响，特别是对于远距离的物体，在低线束(16线)激光雷达中可能只有稀疏的几个点，完全无法分辨。然而高线束的激光雷达价格十分昂贵(以 Velodyne 64线激光雷达为例，其价格高达十几万美金)，因此多数无人驾驶技术方案都需要在性能与价格之间做出权衡。

从使用数据的类型来看，目前针对三维环境的物体检测技术主要分为三大方向：基于图像的方案，基于点云数据的方案，以及多传感器数据融合方案。 尽管如此，绝大多数方案都局限于使用一帧数据进行检测。 对于真实场景的检测任务来说，数据都是以流的形式连续获取的。相比于单帧数据，流数据可以提供同一目标在一段时间内的信息，该信息有利于检测算法筛除误检测的目标，这是因为噪声在时序上的连续性较差。另一方面，对于遮挡以及边界截断的目标，在流数据中可以利用前后帧的信息对其进行补全。另外一点值得注意的是，流数据有很强的数据冗余性，如果使用单帧物体检测算法，则需要逐帧进行检测，十分耗时；但是如果使用针对流数据的检测算法，则可以只对少数关键帧进行检测，然后将检测结果传播到非关键帧。 因此，开发专门针对流数据的三维物体检测算法，能显著提高物体检测的准确率与效率。这从算法的落地来看，是十分有实践意义的。 

\section{国内外研究进展}
\label{sec:realted_work}
目前国内外针对流数据的三维物体检测研究还较少，而基于单帧数据的三维物体检测以及基于视频流的二维物体检测的研究较为丰富。 因此，本节分别从三维物体检测以及视频流物体检测概述前沿进展。 另外，三维场景的多目标追踪研究进展也会进行简要说明。

\subsection{三维物体检测}
\label{3d_detect}
目前大多数三维检测研究可以归类为三大方向：基于图像，基于点云，以及基于多传感器融合。 

(1)基于图像的方法。 基于图像的三维物体检测以 Mono3D \cite{7780605} 和 3DOP \cite{chen20183d} 为代表。 这类方法只是用摄像头采集的图像数据，通过多视角图像融合来推断三维信息。由于图像数据没有深度信息，这类方法需要人工设计的几何特征来表征物体的深度信息，虽然数据采集简单，速度快，但是检测精度差。 最近越来越多研究者探索基于双目摄像头数据的三维物体检测，例如 [TODO]。 这类方法通过神经网络融合左右摄像头的数据来预测物体的三维信息， 从生物学上来说很接近人类的双眼视觉系统。 然而由于神经网络的不确定性，以及双目视觉盲区的存在，该方法仍然有很多亟待解决的问题。

(2)基于点云的方法。 基于点云的方法可分为一步法和两步法。 一步法即直接是端对端预测物体的三维位姿，这类方法根据点云的编码方式不同又可分为基于体素的方法以及基于投影的方法。 基于体素的方法使用三维体素网格编码点云特征， 每个体素立方体的值由该立方体内的点决定，从而将不规则的三维点云数据编码成规则的三维体素数据， 便于后续使用神经网络进行特征提取。 代表有 3D FCN \cite{li20173d}， Vote3Deep \cite{engelcke2017vote3deep}以及 VoxelNet \cite{zhou2018voxelnet}等。 这类方法的一大缺点是体素大小不好确定，太大的话信息损失严重，太小则会造成巨大的计算量。 另外，这类方法需要使用到三维卷积，因此很耗计算资源。 基于投影的方法是将点云在高度方向进行投影，将三维数据降维成二维的俯视图(BEV， bird eye view)数据。 考虑到驾驶场景中， 道路基本是共面且水平的，因此在高度方向上投影对物体的位姿信息基本没有损失。 经过投影操作后，就能直接使用二维图像物体检测的方法进行物体检测。 PIXOR \cite{yang2018pixor} 以及 Complex-YOLO \cite{simon2018complex,Simon_2019_CVPR_Workshops} 等属于这类方法。 虽然降维能够带来速度的极大提升，然而由于点云数据的稀疏性，经过投影后目标的特征点损失很严重。 特征点的不足会很大程度上影响检测结果的准确性，特别是对于远处的目标以及小目标。 两步法的思路是先对点云进行分割， 然后对于分割结果的每一个目标进行框回归，得到目标的三维位姿信息。 这类方法的代表有 \cite{shi2019pointrcnn}。 两步法的不足之处是其检测结果非常依赖于分割结果，且在框回归中，对于点较少的远处目标，三维位姿信息的恢复效果并不好。

(3)基于多传感器融合的方法。 点云的稀疏性以及图像缺少深度信息都限制着相应方法的准确率，一个自然而然的想法就是能不能将这两种数据融合， 从而达到更好的检测结果。 基于多传感器融合的方法通过算法融合点云数据以及图像数据，从而提升三维物体检测的准确率。 这类方法的代表有 F-PointNet \cite{qi2018frustum}， MV3D \cite{chen2017multi}， AVOD \cite{ku2018joint}等。 这些方法的区别主要在于融合的方式不同， F-PointNet 首先使用二维物体检测方法检测出图像中的所有物体，之后对于每个物体，将其反投影回点云中得到一个视锥区域，对该区域内的点进行分割然后再进行框回归。该方法通过先在图像中找出目标，从而减少了在点云空间的搜索区域。然而，该算法的准确率受二维物体检测很大，在第一步没有检测出的物体，之后没有其他办法弥补。 MV3D 将二维物体检测中的的区域提取网络 (Region Proposal Network， RPN) 扩展到三维， 提出了 3D RPN 分别提取点云以及图像特征， 然后通过一个特征融合模块得到融合特征，最后进行三维物体检测。 AVOD 在 MV3D 的基础上改进了特征提取模块， 引入的金字塔结构从而能够得到全分辨率的特征图， 提升了物体的定位精度，特别对于小物体。 本文工作基于 AVOD 框架并进行了改进， 使其能支持多针输入， 并且引入了时序信息处理模块。

\subsection{视频流物体检测}
\label{video_detect}
视频流物体检测与单帧物体检测的主要区别在于是否利用了时序信息。 对于视频流物体检测，时序信息是物体的位姿在时间上的连续性的抽象体现。 目前，大多数视频流物体检测方法都是在两个层面利用时序信息，特征提取层面以及最终的框回归层面。 对于特征处理层面， 一般是根据运动信息将前后帧的的特征整合到关键帧，以增加关键帧的物体特征。 这个过程中需要使用到光流信息，即图像中各像素点的运动方向。 代表有 FGFA \cite{zhu2017flow}系列工作。 一般来说光流信息的获取比较困难，这也是限制该方法进一步发展的主要障碍。 对于在框回归层面利用时序信息，主要的工作有 T-CNN \cite{kang2018t， kang2016object} 与 Seq-NMS \cite{han2016seq}等。 T-CNN 使用预先计算的光流信息将关键帧的检测结果传播到临近帧，而 Seq-NMS 则是通过整合连续几帧的高置信度的候选框来提升目标检测中非极大值抑制(Non-Maximum Suppression，NMS)算法的性能。 最近， 也有一些工作试图通过神经网络学习连续帧之间的的时序信息， 从而避免使用高代价的光流数据。 这类方法的代表有 D\&T \cite{feichtenhofer2017detect}。 D\&T 提出了一个双路目标检测网络，可以同时时间视频流的目标检测以及目标追踪。 该网络可以输入多帧数据进行检测， 并且通过互相关操作(Cross-correlation) 来学习相邻帧之间相同物体的对应关系以及偏移。 本文的算法框架在一定程度上也借鉴了 D\&T 的结构， 不过我们在他的基础上进行了很大的改进，使其能够适应三维物体的流数据检测。

\subsection{三维多目标追踪}
\label{tracking}
目前基本上所有的三维多目标追踪方法都是先对流数据的每一帧进行目标检测，然后再将这些检测框关联起来， 这种范式也被称为 \textit{Tracking by Detection} \cite{lenz2015followme}。 三维多目标追踪的工作有很多，比较有代表性的有 FaF \cite{luo2018fast}， 3D-CNN/PMBM \cite{scheidegger2018mono}以及 DSM \cite{frossard2018end}等。 FaF 使用首先将点云流数据结构化成四维张量，然后构建了一个简单的特征提取网络提取特征，最后使用不同的网络头分别预测得到三维目标检测，多目标追踪以及运动方向预测结果。该方法能够整合前 $n$ 帧的检测结果得到精确的物体运动轨迹。 然而该方法计算量巨大， 并且网络参数调节需要有很高的技巧。  3D-CNN/PMBM 首先构建神经网络从单张图像预测物体的三维位姿， 然后将所有帧的检测框送入泊松多重伯努利 (Poisson Multi-Bernoulli Mixture， PMBM) 混合追踪滤波器进行滤波，得到最终的三维多目标追踪结果。 该方法只使用单帧图像进行三维目标检测，效果有限。 DSM 首先使用单帧三维物体检测框架 MV3D \cite{chen2017multi} 对每一帧数据进行物体检测得到三维检测框， 然后通过一个匹配网络(\textit{Matching net})以及得分网络(\textit{Scoring net})关联所有的检测框。 该方法需要对每一帧数据都进行检测， 并且帧与帧之间的时序信息基本上没有被使用，因此不是针对流数据的高效方法。

\section{本文工作及创新点}
\label{subsec:contribution}
本文提出了一个双路物体检测与追踪(\textbf{D}ual-way \textbf{O}bject \textbf{D}etection and \textbf{T}racking， \textbf{DODT})框架， 实现了流数据场景的高效三维物体检测与追踪。 本框架的构建是基于以下几个观察： (1) 点云能够与图像融合从而丰富物体的视觉特征， 这点在 \cite{chen2017multi,ku2018joint}中得到了证实; (2) 除了通过光流数据， 时序信息也能够通过计算相邻帧间的互相关信息，这点通过 \cite{feichtenhofer2017detect} 也能够得到验证; (3) 特征在连续帧之间的变化是连续的， 我们可以只对关键帧进行检测，然后将结果传播到非关键帧， 这样可以极大的减少计算量。 对于第一点， 本文借用了 AVOD\cite{ku2018joint} 中的数据融合方案，将点云数据提供的 BEV 信息与图像融合。 对于第二点， 本文构建了一个时序模块(Temporal module)， 该模块使用互相光操作在 BEV 空间中计算相邻关键帧的时序特征， 然后预测相同物体在不同关键帧中同时出现的概率以及偏移量。 与 \cite{feichtenhofer2017detect,dosovitskiy2015flownet} 不同的是， 本模块的互相关操作是在后候选框层面进行的，不需要全局计算， 这极大地提高了模块的运行效率。 对于最后一点， 我们将 DODT 框架的目标检测模块设计成了双路结构， 这样该模块就能够同时输入两帧相邻关键帧， 以保证后面时序模块的正确运行。 另外， 为了进一步提高框架的效率， 本文还设计了一个共享 RPN (Shared Region Proposal Network， Shared RPN) 模块， 该模块可以生成供两检测分支共同使用的三维候选框。 最后，为了生成所有帧的检测结果， 本文设计了一个基于运动的框插值算法， 该算法利用关键帧的检测结果以及时序模块预测的信息，插值生成非关键帧的检测结果。 同时， 该差值算法还能够将不同帧的候选框关联起来， 得到多目标追踪结果。

本文的贡献及创新点如下：
\begin{itemize}
	\item 本文提出了名为 DODT 的双路网络， 该网络能够同时精确地完成基于流数据的三维物体检测以及多目标追踪任务。
	\item 本文提出了一个时序模块在候选框层面上编码相邻关键帧之间的时序信息， 相比于\cite{feichtenhofer2017detect,dosovitskiy2015flownet}中方法， 该方法更加灵活，也更加高效。
	\item 本文设计了一个共享 RPN 模块， 能够显著提高相邻多帧目标检测中候选框提取的效率。
	\item 本文开发了一个基于运动的框插值算法， 能够有效的将关键帧的预测框传播到非关键帧， 同时也能够将所有框关联起来， 实现多目标追踪。
\end{itemize}


\section{文章组织与结构}
\label{subsec:structure}
本文的主要内容分为五章。 第一章为引言， 介绍项目的研究背景和意义， 国内外的研究进展以及本文工作的简单介绍和创新点; 第二章介绍本工作涉及到的一些技术的基础理论， 分为目标检测与目标追踪两大块； 第三章详细地介绍了本文提出的框架的构造和原理， 是全文的重点内容； 第四章主要是介绍了本项目的实验设计， 结果展示以及实验结果分析， 该部分也是全文的重点内容； 最后一章总结本文的工作， 然后介绍本文工作的不足之处以及后续的实验计划。 


% 打印时插入必要的空白页
\ifprint
	\newpage
	\thispagestyle{empty}
	\mbox{}
	
	% 避免空白页影响页码编号
	\clearpage
	\setcounter{page}{10}
\fi